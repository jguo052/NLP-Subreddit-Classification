{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab34c03-27d6-4709-84b8-ca815eb42603",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b371dc-4221-47b8-94dc-adee19c244b0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a746533-b640-4c61-98fe-2c6d889eff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import datetime as dt\n",
    "\n",
    "# core\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# transformers\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, \\\n",
    "                            GradientBoostingClassifier, StackingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a276e8bc-be85-457b-8039-7b903df32bb6",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ecd06-e737-4568-8964-ca9962a7a0e3",
   "metadata": {},
   "source": [
    "Our last major goal is to create a model predicts whether a post belongs r/Seattle or r/SeattleWA. Let us read in the data once more and train-test-split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e74827e-45ea-4aed-b2ed-47dc278bc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in r/Seattle and r/SeattleWA data\n",
    "sea = pd.read_csv('datasets/Cleaned_Seattle.csv')\n",
    "sea_wa = pd.read_csv('datasets/Cleaned_SeattleWA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e064350-ccf3-490a-a66e-2aa0e0ff3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine r/Seattle and r/SeattleWA data into single DataFrame\n",
    "all_posts = pd.concat([sea, sea_wa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c45d822-3994-49c9-ba09-cc51922ea0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Seattle to 0 and SeattleWA to 1 in subreddit column\n",
    "all_posts['subreddit'] = all_posts['subreddit'].map({'Seattle': 0, 'SeattleWA': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061bd318-5157-43a1-9e76-e617e3524434",
   "metadata": {},
   "source": [
    "Our first group of models will use strictly text data to predict the subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc5b9d5f-7d77-4606-96ce-3a3879ce1eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X (text) and y (subreddit)\n",
    "X = all_posts['text']\n",
    "y = all_posts['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e29e293b-1274-44b0-985f-2892074c0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe60130-86ad-40b8-bd23-08ed3dbe9f35",
   "metadata": {},
   "source": [
    "#### Baseline Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff5cdd-f659-4c8e-bd25-b25a70c2dc70",
   "metadata": {},
   "source": [
    "Before we begin modeling, we should first determine establish a baseline score. Intuitively, each subreddit accounts for roughly 50% of the posts in the dataset. If we classified any predictions as the same subreddit everytime, we would epect 50% of our predictions to be correct. This is confirmed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3002b09c-85b8-4301-a587-7939026d75ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.503536\n",
       "1    0.496464\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa052d-a1f7-4fd1-af65-553fd0e324ce",
   "metadata": {},
   "source": [
    "Since the two subreddits are very similar and many people likely post on either subreddit without much thought, there is a level of randomness that we simply will not be able to predict. I would be very pleasantly surprised if our model achieves greater than 60% accuracy.\n",
    "\n",
    "There are numerous metrics besides accuracy that one can use to assess a classification model. Since our classes are balanced and optimizing false positives seems equivalently valuable to optimizing false negatives, optimizing accuracy seems sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e710266-271d-4852-9cde-c6538487c914",
   "metadata": {},
   "source": [
    "## Modeling with CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b8e52-4946-4363-894b-22638b5ca6c7",
   "metadata": {},
   "source": [
    "Two straightforward ways to vectorize string data is with `CountVectorizer` and `TfidfVectorizer`. We will first fit a batch of classification models with `CountVectorizer` using Pipelines and GridSearchCV. The hyperparameters chosen below are all after several iterations of hyperparameter tuning.\n",
    "\n",
    "The classification models we will try first are:\n",
    "- logistic regression\n",
    "- bagging\n",
    "- random forest\n",
    "- AdaBoost\n",
    "- gradient boosting\n",
    "- multinomial naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ec56b-c453-41ce-b668-a50f754bb718",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85c9eeee-5e57-4724-b6e3-c5b9386f2b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             param_grid={'cvec__max_df': [0.8, 0.825],\n",
       "                         'cvec__max_features': [7000, 7500],\n",
       "                         'cvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': ['english'],\n",
       "                         'lr__max_iter': [200]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cvec_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(random_state = 42))\n",
    "])\n",
    "\n",
    "log_cvec_params = {\n",
    "    'cvec__max_features': [7000, 7500],\n",
    "    'cvec__max_df': [0.8, 0.825],\n",
    "    'cvec__stop_words': ['english'],\n",
    "    'cvec__ngram_range': [(1,2), (1,3)],\n",
    "    'lr__max_iter': [200]\n",
    "}\n",
    "\n",
    "log_cvec_gs = GridSearchCV(log_cvec_pipe,\n",
    "                     param_grid = log_cvec_params)\n",
    "\n",
    "log_cvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "88a381ea-cc58-42cd-8d36-cf661bae0c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': 7500, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': 'english', 'lr__max_iter': 200}\n",
      "Train: 0.98464025869038\n",
      "Test: 0.5411954765751211\n"
     ]
    }
   ],
   "source": [
    "print(log_cvec_gs.best_params_)\n",
    "print('Train:', log_cvec_gs.score(X_train, y_train))\n",
    "print('Test:', log_cvec_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a9780-5393-4b31-bf3a-896cdfe45a81",
   "metadata": {},
   "source": [
    "Our model is massively overfit. I am quite surprised to see this much overfitting with logistic regression but we are using 7,500 features. I am however very happy to see an accuracy score of 54%.\n",
    "\n",
    "*Initially I tried using max features hyperparameter values near 2,000 since I saw the most value in looking at the top 2,000 words during my analysis. GridSearchCV reminded me that there were more than 10,000 words and that I could try to incorporate more words into the model than the analysis.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d64984-229e-4dc9-9404-5063f701c0ea",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8770c255-c465-4c92-84b5-9d8539e89ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('bag',\n",
       "                                        BaggingClassifier(random_state=42))]),\n",
       "             param_grid={'bag__max_features': [0.6, 0.8, 1],\n",
       "                         'bag__n_estimators': [7, 10, 15],\n",
       "                         'cvec__max_df': [0.8, 0.825],\n",
       "                         'cvec__max_features': [7000, 7500],\n",
       "                         'cvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': ['english']})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_cvec_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('bag', BaggingClassifier(random_state = 42))\n",
    "])\n",
    "\n",
    "bag_cvec_params = {\n",
    "    'cvec__max_features': [7000, 7500],\n",
    "    'cvec__max_df': [0.8, 0.825],\n",
    "    'cvec__stop_words': ['english'],\n",
    "    'cvec__ngram_range': [(1,2), (1,3)],\n",
    "    'bag__n_estimators': [7, 10, 15],\n",
    "    'bag__max_features': [0.6, 0.8, 1],\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "bag_cvec_gs = GridSearchCV(bag_cvec_pipe,\n",
    "                     param_grid = bag_cvec_params)\n",
    "\n",
    "bag_cvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8e0c0c28-69c8-4d0f-a326-947a945bda93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bag__max_features': 0.6, 'bag__n_estimators': 15, 'cvec__max_df': 0.8, 'cvec__max_features': 7500, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english'}\n",
      "Train: 0.9908380490433846\n",
      "Test: 0.5379644588045234\n"
     ]
    }
   ],
   "source": [
    "print(bag_cvec_gs.best_params_)\n",
    "print('Train:', bag_cvec_gs.score(X_train, y_train))\n",
    "print('Test:', bag_cvec_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c020a307-f898-42bf-9648-3408562f0101",
   "metadata": {},
   "source": [
    "It is not nearly as surprising that bagging produced a very overfit model compared to logistic regression since bagging averages the results of many decision trees. I was hopeful that using smaller choices of `max_features` would combat the overfitting, but even after GridSearchCV chose a value of 0.6, the model is still very overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb81f4-cd64-4b80-b33a-768f5d578a11",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52b9757-d1d9-4bff-979a-3d5b484c107f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             param_grid={'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [7000, 7500],\n",
       "                         'cvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': ['english'],\n",
       "                         'rf__max_samples': [0.4, 0.6, 1],\n",
       "                         'rf__n_estimators': [150, 200]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cvec_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state = 42))\n",
    "])\n",
    "\n",
    "rf_cvec_params = {\n",
    "    'cvec__max_features': [7000, 7500],\n",
    "    'cvec__max_df': [0.8, 0.85],\n",
    "    'cvec__stop_words': ['english'],\n",
    "    'cvec__ngram_range': [(1,2), (1,3)],\n",
    "    'rf__n_estimators': [150, 200],\n",
    "    'rf__max_samples': [0.4, 0.6, 1],\n",
    "\n",
    "}\n",
    "\n",
    "rf_cvec_gs = GridSearchCV(rf_cvec_pipe,\n",
    "                     param_grid = rf_cvec_params)\n",
    "\n",
    "rf_cvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c22b593c-71b6-42ae-9812-1cd002fe4b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': 7000, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english', 'rf__max_samples': 0.6, 'rf__n_estimators': 200}\n",
      "Train: 0.9913769873349502\n",
      "Test: 0.5678513731825525\n"
     ]
    }
   ],
   "source": [
    "print(rf_cvec_gs.best_params_)\n",
    "print('Train:', rf_cvec_gs.score(X_train, y_train))\n",
    "print('Test:', rf_cvec_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc18528c-87f1-440e-9719-6bd8ae60ee8f",
   "metadata": {},
   "source": [
    "This is our best performing model so far! Again, it is very overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e730bc70-00fe-4f52-8849-b563921ee6fb",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f5ec3e-8e24-444e-9a32-1c83d1954164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('ada',\n",
       "                                        AdaBoostClassifier(random_state=42))]),\n",
       "             param_grid={'ada__n_estimators': [50, 75, 100],\n",
       "                         'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [6500, 7000],\n",
       "                         'cvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': ['english']})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cvec_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('ada', AdaBoostClassifier(random_state = 42))\n",
    "])\n",
    "\n",
    "ada_cvec_params = {\n",
    "    'cvec__max_features': [6500, 7000],\n",
    "    'cvec__max_df': [0.8, 0.85],\n",
    "    'cvec__stop_words': ['english'],\n",
    "    'cvec__ngram_range': [(1,2), (1,3)],\n",
    "    'ada__n_estimators': [50, 75, 100],\n",
    "\n",
    "}\n",
    "\n",
    "ada_cvec_gs = GridSearchCV(ada_cvec_pipe,\n",
    "                     param_grid = ada_cvec_params)\n",
    "\n",
    "ada_cvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "52530b2e-7241-45ad-9ef4-6b3e1e691bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ada__n_estimators': 75, 'cvec__max_df': 0.8, 'cvec__max_features': 6500, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english'}\n",
      "Train: 0.646456480732956\n",
      "Test: 0.5395799676898223\n"
     ]
    }
   ],
   "source": [
    "print(ada_cvec_gs.best_params_)\n",
    "print('Train:', ada_cvec_gs.score(X_train, y_train))\n",
    "print('Test:', ada_cvec_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b4dd9-f0db-425e-a584-fe991e78747d",
   "metadata": {},
   "source": [
    "This is our first model that shows significantly less signs of overfitting. Its test score is on the lower end of what we have seen so far, but it is reassuring to see less overfitting even if we do not end up using this model. Unfortunately, AdaBoost has less hyperparameters to tune, and it has settled on an `n_estimators` value between two others. There is likely not much we can do to improve this model besides zero in more precisely on a better `n_estimators` value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f891b96-64ec-4155-beb2-2b7470881342",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd05e69-9c01-40ec-991b-d8191b167a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('gb',\n",
       "                                        GradientBoostingClassifier(random_state=42))]),\n",
       "             param_grid={'cvec__max_df': [0.8, 0.85],\n",
       "                         'cvec__max_features': [7000, 7500],\n",
       "                         'cvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': ['english'],\n",
       "                         'gb__max_depth': [4, 5],\n",
       "                         'gb__n_estimators': [100, 150],\n",
       "                         'gb__subsample': [0.5, 0.6, 0.7]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cvec_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('gb', GradientBoostingClassifier(random_state = 42))\n",
    "])\n",
    "\n",
    "gb_cvec_params = {\n",
    "    'cvec__max_features': [7000, 7500],\n",
    "    'cvec__max_df': [0.8, 0.85],\n",
    "    'cvec__stop_words': ['english'],\n",
    "    'cvec__ngram_range': [(1,2), (1,3)],\n",
    "    'gb__n_estimators': [100, 150],\n",
    "    'gb__subsample': [0.5, 0.6, 0.7],\n",
    "    'gb__max_depth': [4, 5]\n",
    "\n",
    "}\n",
    "\n",
    "gb_cvec_gs = GridSearchCV(gb_cvec_pipe,\n",
    "                     param_grid = gb_cvec_params)\n",
    "\n",
    "gb_cvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d571340b-79e2-4379-a88e-87fd3555d5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.8, 'cvec__max_features': 7000, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english', 'gb__max_depth': 5, 'gb__n_estimators': 100, 'gb__subsample': 0.7}\n",
      "Train: 0.8270008084074374\n",
      "Test: 0.5525040387722132\n"
     ]
    }
   ],
   "source": [
    "print(gb_cvec_gs.best_params_)\n",
    "print('Train:', gb_cvec_gs.score(X_train, y_train))\n",
    "print('Test:', gb_cvec_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8415aec-a0aa-4edc-a216-e48846e1915a",
   "metadata": {},
   "source": [
    "These are very solid scores from Gradient Boosting. Again, this model is very overfit, but still significantly less so than the other models we have fit besides AdaBoost. It also showcased a solid test score and should be considered for a production model unless an upcoming model proves to be better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9904de2-a5aa-4df6-9d9a-9269d789496c",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "013eeac2-a4ff-43ab-9c9d-e89afee39bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'cvec__max_df': [0.825, 0.85],\n",
       "                         'cvec__max_features': [7000, 7500],\n",
       "                         'cvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': ['english']})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cvec_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "nb_cvec_params = {\n",
    "    'cvec__max_features': [7000, 7500],\n",
    "    'cvec__max_df': [0.825, 0.85],\n",
    "    'cvec__stop_words': ['english'],\n",
    "    'cvec__ngram_range': [(1,2), (1,3)],\n",
    "}\n",
    "\n",
    "nb_cvec_gs = GridSearchCV(nb_cvec_pipe,\n",
    "                     param_grid = nb_cvec_params)\n",
    "\n",
    "nb_cvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "baacae7d-90aa-497f-8e7b-0a23883852e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.825, 'cvec__max_features': 7000, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english'}\n",
      "Train: 0.8264618701158717\n",
      "Test: 0.555735056542811\n"
     ]
    }
   ],
   "source": [
    "print(nb_cvec_gs.best_params_)\n",
    "print('Train:', nb_cvec_gs.score(X_train, y_train))\n",
    "print('Test:', nb_cvec_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a883f2f3-4fb9-4088-901b-7cb0e6d6c5a8",
   "metadata": {},
   "source": [
    "We see very comparable scores between Multinomial Bayes and Gradient Boosting without having to do any hyperparameter tuning required for the ensemble models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fb9fe-15a5-4b1f-abea-3c43e36e872c",
   "metadata": {},
   "source": [
    "## Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc102c4-ba54-4852-a225-abbe44d6b0b1",
   "metadata": {},
   "source": [
    "So far some accuracy scores above 55% from Random Forest, Gradient Boosting, and Multinomial Naive Bayes when we use CountVectorizer as a text transformer. Let us see if we get any increased performance by using TfidfVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c29cf-59ae-4fc0-a5fd-4c5624db6e70",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec1441cd-e2bb-4367-b76d-31b51ef80189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             param_grid={'lr__max_iter': [100, 200],\n",
       "                         'tvec__max_df': [0.8, 0.85],\n",
       "                         'tvec__max_features': [7000, 7500],\n",
       "                         'tvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'tvec__stop_words': ['english']})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_tvec_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(random_state = 42))\n",
    "])\n",
    "\n",
    "log_tvec_params = {\n",
    "    'tvec__max_features': [7000, 7500],\n",
    "    'tvec__max_df': [0.8, 0.85],\n",
    "    'tvec__stop_words': ['english'],\n",
    "    'tvec__ngram_range': [(1,2), (1,3)],\n",
    "    'lr__max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "log_tvec_gs = GridSearchCV(log_tvec_pipe,\n",
    "                     param_grid = log_tvec_params)\n",
    "\n",
    "log_tvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "76070fee-6339-4c5a-8c48-d5966c1fec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__max_iter': 100, 'tvec__max_df': 0.8, 'tvec__max_features': 7000, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': 'english'}\n",
      "Train: 0.8563729452977634\n",
      "Test: 0.5662358642972536\n"
     ]
    }
   ],
   "source": [
    "print(log_tvec_gs.best_params_)\n",
    "print('Train:', log_tvec_gs.score(X_train, y_train))\n",
    "print('Test:', log_tvec_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f038ced-f510-41c8-9ed1-6d3faa5b6524",
   "metadata": {},
   "source": [
    "This model looks much better than the previous logistic regression model. It was way less overfit and boasts our second highest test score so far, after Random Forest. Since logistic regression attains nearly the same test score here with much less overfitting, this is a wonderful candidate for a production model. Moreover, there is the added benefit of interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f51e67-cbff-41c8-ad86-299b0b116f4f",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ac36681-7ac3-490d-a9a8-0354ba41e042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('bag',\n",
       "                                        BaggingClassifier(random_state=42))]),\n",
       "             param_grid={'bag__max_features': [0.7, 0.8],\n",
       "                         'bag__n_estimators': [7, 10, 15],\n",
       "                         'tvec__max_df': [0.8, 0.85],\n",
       "                         'tvec__max_features': [7000, 7500],\n",
       "                         'tvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'tvec__stop_words': ['english']})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_tvec_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('bag', BaggingClassifier(random_state = 42))\n",
    "])\n",
    "\n",
    "bag_tvec_params = {\n",
    "    'tvec__max_features': [7000, 7500],\n",
    "    'tvec__max_df': [0.8, 0.85],\n",
    "    'tvec__stop_words': ['english'],\n",
    "    'tvec__ngram_range': [(1,2), (1,3)],\n",
    "    'bag__n_estimators': [7, 10, 15],\n",
    "    'bag__max_features': [0.7, 0.8],\n",
    "}\n",
    "\n",
    "bag_tvec_gs = GridSearchCV(bag_tvec_pipe,\n",
    "                     param_grid = bag_tvec_params)\n",
    "\n",
    "bag_tvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9c922a2c-9aed-48fe-a1c0-cc96150b364e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bag__max_features': 0.7, 'bag__n_estimators': 15, 'tvec__max_df': 0.8, 'tvec__max_features': 7500, 'tvec__ngram_range': (1, 2), 'tvec__stop_words': 'english'}\n",
      "Train: 0.9916464564807329\n",
      "Test: 0.5290791599353797\n"
     ]
    }
   ],
   "source": [
    "print(bag_tvec_gs.best_params_)\n",
    "print('Train:', bag_tvec_gs.score(X_train, y_train))\n",
    "print('Test:', bag_tvec_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89337948-484d-4313-9e0c-1f8649f2bbbb",
   "metadata": {},
   "source": [
    "Yet again, bagging performs poorly. It is still very overfit and holds the current worst test score, second to the previous bagging model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18594c2d-6f68-4b23-8811-ce30034f2398",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51ccd6ae-800c-4560-9c8c-cce799ddb3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             param_grid={'rf__max_samples': [0.4, 0.5],\n",
       "                         'rf__n_estimators': [150, 200],\n",
       "                         'tvec__max_df': [0.825, 0.85],\n",
       "                         'tvec__max_features': [7000, 7500],\n",
       "                         'tvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'tvec__stop_words': ['english']})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tvec_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state = 42))\n",
    "])\n",
    "\n",
    "rf_tvec_params = {\n",
    "    'tvec__max_features': [7000, 7500],\n",
    "    'tvec__max_df': [0.825, 0.85],\n",
    "    'tvec__stop_words': ['english'],\n",
    "    'tvec__ngram_range': [(1,2), (1,3)],\n",
    "    'rf__n_estimators': [150, 200],\n",
    "    'rf__max_samples': [0.4, 0.5],\n",
    "}\n",
    "\n",
    "rf_tvec_gs = GridSearchCV(rf_tvec_pipe,\n",
    "                     param_grid = rf_tvec_params)\n",
    "\n",
    "rf_tvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d2f56ddd-82cd-42aa-8d06-57832bf0d2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__max_samples': 0.5, 'rf__n_estimators': 200, 'tvec__max_df': 0.825, 'tvec__max_features': 7000, 'tvec__ngram_range': (1, 2), 'tvec__stop_words': 'english'}\n",
      "Train: 0.9900296416060361\n",
      "Test: 0.5452342487883683\n"
     ]
    }
   ],
   "source": [
    "print(rf_tvec_gs.best_params_)\n",
    "print('Train:', rf_tvec_gs.score(X_train, y_train))\n",
    "print('Test:', rf_tvec_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e9eba8-d742-4c98-b897-1e206d753fb0",
   "metadata": {},
   "source": [
    "This time Random Forest performs a bit worse with the TfidfVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce89ae-3f90-4429-8b80-edb566109b7f",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fa5fc5b-ac9c-4aa7-8a9a-e1ab37c47bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('ada',\n",
       "                                        AdaBoostClassifier(random_state=42))]),\n",
       "             param_grid={'ada__n_estimators': [100, 125],\n",
       "                         'tvec__max_df': [0.8, 0.825],\n",
       "                         'tvec__max_features': [7000, 7500],\n",
       "                         'tvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'tvec__stop_words': ['english']})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_tvec_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('ada', AdaBoostClassifier(random_state = 42))\n",
    "])\n",
    "\n",
    "ada_tvec_params = {\n",
    "    'tvec__max_features': [7000, 7500],\n",
    "    'tvec__max_df': [0.8, 0.825],\n",
    "    'tvec__stop_words': ['english'],\n",
    "    'tvec__ngram_range': [(1,2), (1,3)],\n",
    "    'ada__n_estimators': [100, 125]\n",
    "}\n",
    "\n",
    "ada_tvec_gs = GridSearchCV(ada_tvec_pipe,\n",
    "                     param_grid = ada_tvec_params)\n",
    "\n",
    "ada_tvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fb688fdd-dfe2-49af-87ff-68338eed545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ada__n_estimators': 125, 'tvec__max_df': 0.8, 'tvec__max_features': 7000, 'tvec__ngram_range': (1, 2), 'tvec__stop_words': 'english'}\n",
      "Train: 0.7178658043654002\n",
      "Test: 0.5460420032310178\n"
     ]
    }
   ],
   "source": [
    "print(ada_tvec_gs.best_params_)\n",
    "print('Train:', ada_tvec_gs.score(X_train, y_train))\n",
    "print('Test:', ada_tvec_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b382d-f495-47ed-a466-7ac8336ab97e",
   "metadata": {},
   "source": [
    "AdaBoost again produces one of the least overfit models. The score is quite respectable, but at this point we have seen enough stronger scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab73248-bae6-4800-aa60-9ac8fde97722",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b22252a-c73a-41c6-b38c-345c6da6dcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('gb',\n",
       "                                        GradientBoostingClassifier(random_state=42))]),\n",
       "             param_grid={'gb__max_depth': [4, 5],\n",
       "                         'gb__n_estimators': [100, 125],\n",
       "                         'gb__subsample': [0.4, 0.5],\n",
       "                         'tvec__max_df': [0.8, 0.85],\n",
       "                         'tvec__max_features': [7000, 7500],\n",
       "                         'tvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'tvec__stop_words': ['english']})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_tvec_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('gb', GradientBoostingClassifier(random_state = 42))\n",
    "])\n",
    "\n",
    "gb_tvec_params = {\n",
    "    'tvec__max_features': [7000, 7500],\n",
    "    'tvec__max_df': [0.8, 0.85],\n",
    "    'tvec__stop_words': ['english'],\n",
    "    'tvec__ngram_range': [(1,2), (1,3)],\n",
    "    'gb__n_estimators': [100, 125],\n",
    "    'gb__subsample': [0.4, 0.5],\n",
    "    'gb__max_depth': [4, 5]\n",
    "}\n",
    "\n",
    "gb_tvec_gs = GridSearchCV(gb_tvec_pipe,\n",
    "                     param_grid = gb_tvec_params)\n",
    "\n",
    "gb_tvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8b6afabf-e192-4237-a145-ad449cc469ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gb__max_depth': 4, 'gb__n_estimators': 125, 'gb__subsample': 0.5, 'tvec__max_df': 0.8, 'tvec__max_features': 7500, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': 'english'}\n",
      "Train: 0.8229587712206953\n",
      "Test: 0.5323101777059773\n"
     ]
    }
   ],
   "source": [
    "print(gb_tvec_gs.best_params_)\n",
    "print('Train:', gb_tvec_gs.score(X_train, y_train))\n",
    "print('Test:', gb_tvec_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742a308-26a2-423b-abd3-83b8898ec47a",
   "metadata": {},
   "source": [
    "Like the AdaBoost model, Gradient Boosting with the TfidfVectorizer performed worse this time. We could try to do more hyperparameter tuning, but Gradient Boosting has more choices than others and seems to take a bit more time to fit. We should only come back to this if we have spare time and we are interested in even unlikely improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafdc87a-fbde-4aad-98f7-27b0ee8386c8",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2e0169b-431c-41c2-89ff-88425bd58977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'tvec__max_df': [0.8, 0.825, 0.85],\n",
       "                         'tvec__max_features': [7250, 7500, 7750],\n",
       "                         'tvec__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'tvec__stop_words': ['english']})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tvec_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "nb_tvec_params = {\n",
    "    'tvec__max_features': [7250, 7500, 7750],\n",
    "    'tvec__max_df': [0.8, 0.825, 0.85,],\n",
    "    'tvec__stop_words': ['english'],\n",
    "    'tvec__ngram_range': [(1,2), (1,3)],\n",
    "}\n",
    "\n",
    "nb_tvec_gs = GridSearchCV(nb_tvec_pipe,\n",
    "                     param_grid = nb_tvec_params)\n",
    "\n",
    "nb_tvec_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "314c75e5-2fb3-4f57-ac34-388b533057a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tvec__max_df': 0.8, 'tvec__max_features': 7750, 'tvec__ngram_range': (1, 2), 'tvec__stop_words': 'english'}\n",
      "Train: 0.8609539207760711\n",
      "Test: 0.574313408723748\n"
     ]
    }
   ],
   "source": [
    "print(nb_tvec_gs.best_params_)\n",
    "print('Train:', nb_tvec_gs.score(X_train, y_train))\n",
    "print('Test:', nb_tvec_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11af194a-839f-4749-a568-3db2a419426e",
   "metadata": {},
   "source": [
    "This has been our best model so far by a decent amount. It is the strongest test score and is one of less overfit models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c31fe9f-92ec-4209-aa91-b223f37d4722",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66dffea-5958-4a1a-9718-87097d8a5d91",
   "metadata": {},
   "source": [
    "We have two approaches to combining the results of our strongest models into a single classification model: `VotingClassifer` and `StackingClassifier`. Below, we fit a voting classifier on our best performing models:\n",
    "\n",
    "with `CountVectorizer`:\n",
    "- random forest\n",
    "- gradient boosting\n",
    "- multinomial naive Bayes\n",
    "\n",
    "with `TfidfVectorizer`:\n",
    "- logistic regression\n",
    "- multinomial naive Bayes\n",
    "\n",
    "There is some slight setup we must do before we can fit a voting classifier. To simplify our steps, we create several lists of pipe names, pipes, and the models we fit above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b76450e9-dd00-41a2-871f-7311c60ea1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names for pipes for VotingClassifier\n",
    "top_pipe_names = ['rfc', 'gbc', 'nbc', 'logt','nbt']\n",
    "\n",
    "# pipes for VotingClassifier\n",
    "top_pipes = [rf_cvec_pipe, gb_cvec_pipe, nb_cvec_pipe,\n",
    "         log_tvec_pipe, nb_tvec_pipe]\n",
    "\n",
    "# pregridsearched models with hyperparameters tuned\n",
    "top_models = [rf_cvec_gs, gb_cvec_gs, nb_cvec_gs,\n",
    "                log_tvec_gs, nb_tvec_gs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fac133-7072-4732-b41f-36c3a0a79fcb",
   "metadata": {},
   "source": [
    "To take advantage of the thorough hyperparameter tuning we did earlier, we loop over our models insert the best parameters into the parameters dictionary for our `VotingClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e146db02-0233-4807-bb8d-dc24d7b9cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aliases and pipes for voting classifers\n",
    "top_pipe_tuples = list(zip(top_pipe_names, top_pipes))\n",
    "voters = VotingClassifier(top_pipe_tuples)\n",
    "\n",
    "# voting model paramters\n",
    "voter_params = {}\n",
    "\n",
    "# collect hyperparameters from gridsearch fits for voting classifier\n",
    "for i, model in enumerate(top_models):\n",
    "    for param_name, param_val in model.best_params_.items():\n",
    "        # make sure hyperparameter names are of the form\n",
    "        # (pipe name)__(transformer or estimatorname)__(parameter name)\n",
    "        voter_param_name = top_pipe_names[i] + '__' + param_name\n",
    "        voter_params[voter_param_name] = [param_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "796bf28c-83af-4e6f-86dd-d358f1dd71f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=VotingClassifier(estimators=[('rfc',\n",
       "                                                     Pipeline(steps=[('cvec',\n",
       "                                                                      CountVectorizer()),\n",
       "                                                                     ('rf',\n",
       "                                                                      RandomForestClassifier(random_state=42))])),\n",
       "                                                    ('gbc',\n",
       "                                                     Pipeline(steps=[('cvec',\n",
       "                                                                      CountVectorizer()),\n",
       "                                                                     ('gb',\n",
       "                                                                      GradientBoostingClassifier(random_state=42))])),\n",
       "                                                    ('nbc',\n",
       "                                                     Pipeline(steps=[('cvec',\n",
       "                                                                      CountVectorizer()),\n",
       "                                                                     ('nb',\n",
       "                                                                      MultinomialNB())])),\n",
       "                                                    ('logt',\n",
       "                                                     Pipeline(s...\n",
       "                         'nbc__cvec__stop_words': ['english'],\n",
       "                         'nbt__tvec__max_df': [0.8],\n",
       "                         'nbt__tvec__max_features': [7750],\n",
       "                         'nbt__tvec__ngram_range': [(1, 2)],\n",
       "                         'nbt__tvec__stop_words': ['english'],\n",
       "                         'rfc__cvec__max_df': [0.8],\n",
       "                         'rfc__cvec__max_features': [7000],\n",
       "                         'rfc__cvec__ngram_range': [(1, 2)],\n",
       "                         'rfc__cvec__stop_words': ['english'],\n",
       "                         'rfc__rf__max_samples': [0.6],\n",
       "                         'rfc__rf__n_estimators': [200]})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit voting classifier over best found parameters\n",
    "vote_gs = GridSearchCV(voters, param_grid = voter_params)\n",
    "vote_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a1e9d521-e601-468f-9a31-3ef7cfa8cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.8992185394772299\n",
      "Test: 0.5726978998384491\n"
     ]
    }
   ],
   "source": [
    "print('Train:', vote_gs.score(X_train, y_train))\n",
    "print('Test:', vote_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e9935-818d-43a4-8768-553eee5de420",
   "metadata": {},
   "source": [
    "Our results from multinomial naive Bayes slightly outperforms our voting classifier. So far, I would still use this voting classifier over the multinomial naive Bayes model since it seems more robust, averaging over several of our best models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9468f23d-5560-4922-8868-9bb25f5c1718",
   "metadata": {},
   "source": [
    "## Stacking - Our Production Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d40a2-4726-4582-94b5-f96c9152c1a4",
   "metadata": {},
   "source": [
    "For our final model, we use `StackingClassifiers` over the same models that we used for `VotingClassifier`. Unfortunately, it is not obvious how we can incorporate our hyperparameters into this model, or if it would even be a good idea to do so. Thus we are fitting our stacking model over the base models that performed best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5fcee550-01ce-4457-93bb-f046da716e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rfc',\n",
       "                                Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                                ('rf',\n",
       "                                                 RandomForestClassifier(random_state=42))])),\n",
       "                               ('gbc',\n",
       "                                Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                                ('gb',\n",
       "                                                 GradientBoostingClassifier(random_state=42))])),\n",
       "                               ('nbc',\n",
       "                                Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                                ('nb', MultinomialNB())])),\n",
       "                               ('logt',\n",
       "                                Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                                ('lr',\n",
       "                                                 LogisticRegression(random_state=42))])),\n",
       "                               ('nbt',\n",
       "                                Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                                ('nb', MultinomialNB())]))],\n",
       "                   final_estimator=LogisticRegression(random_state=42))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipe_tuples are already in the form for stacking\n",
    "# due to setup for VotingClassifier\n",
    "stack = StackingClassifier(estimators = pipe_tuples,\n",
    "                                 final_estimator = LogisticRegression(random_state = 42))\n",
    "\n",
    "stack.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d5655db2-8fa4-4ac2-b5d3-6d016265e274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9832929129614659\n",
      "Test: 0.592891760904685\n"
     ]
    }
   ],
   "source": [
    "print('Train:', stack.score(X_train, y_train))\n",
    "print('Test:', stack.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d9ec01-a537-4601-a4f2-eac1db414f67",
   "metadata": {},
   "source": [
    "Like most of the other ensemble models, this model is very overfit. It still outperformed all of our other models by a fairly wide margin. Each model fought for every percentage of predictive power, most getting no more than 5% more than the baseline accuracy score. This stacking model's accuracy exceeded our previous best accuracy by nearly 2%. This is too substantial to ignore and is a clear choice for our production model.\n",
    "\n",
    "Although the level of overfitting makes me someone skepticle of the validity of the test accuracy score, the value is large enough that I believe it is still the strongest model even if performs slightly worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173797e6-aefd-4b74-be27-c15f39414016",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summarizing the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7a2102-d42e-4d9f-a75e-10d22f5155d2",
   "metadata": {},
   "source": [
    "To really compare all of the results we have collected so far, let us create a summative visual. Below we create several lists to help us create this visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d4ef0ff3-da37-428e-b476-653ecc4c08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summative bar chart on model performances\n",
    "# bar labels\n",
    "model_names = ['Log', 'Bag', 'R Forest', 'Ada', 'Gradient', 'Mult NB', 'Vote', 'Stacking']\n",
    "\n",
    "# pregridsearched models with hyperparameters tuned\n",
    "all_models = [log_cvec_gs, bag_cvec_gs, rf_cvec_gs, ada_cvec_gs, gb_cvec_gs, nb_cvec_gs,\n",
    "                log_tvec_gs, bag_tvec_gs, rf_tvec_gs, ada_tvec_gs, gb_tvec_gs, nb_tvec_gs,\n",
    "                vote_gs, stack]\n",
    "\n",
    "# accuracy scores for each classification model\n",
    "all_scores = [model.score(X_test, y_test) for model in all_models]\n",
    "\n",
    "# scores of unused models\n",
    "unused_scores = [0 if i in [2,4,5,6,11,13] else all_scores[i] for i in range(len(all_scores))]\n",
    "\n",
    "# scores of models used for stacking\n",
    "level_1_scores = [all_scores[i] for i in [2,4,5,6,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7a83e909-75d8-4953-801e-39044555ed14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (18,7))\n",
    "\n",
    "# plot title\n",
    "plt.text(s = 'Stacking Performed Best', size = 30, x = 5, y = 0.615)\n",
    "\n",
    "# generate x position of bars and \n",
    "# create model names as x labels for bars\n",
    "x_vals = list(range(1,7)) + list(range(8,14)) + [15,16]\n",
    "x_labels = 2*model_names[:6] + model_names[-2:]\n",
    "plt.xticks(x_vals, labels = x_labels, rotation = 60, size = 15)\n",
    "plt.yticks([0.5, 0.525, 0.55, 0.575, 0.6],size = 15)\n",
    "\n",
    "# plot the bars\n",
    "plt.bar(16, all_scores[-1], width = 0.6, color = 'tab:blue', label = 'Production')\n",
    "plt.bar([3,5,6,8,13], level_1_scores, width = 0.6, color = 'goldenrod', label = 'For Stacking')\n",
    "plt.bar(x_vals, unused_scores, width = 0.6, color = 'tab:grey', label = 'Unused')\n",
    "\n",
    "# shape axes and create axes labels\n",
    "plt.xlim([0,17])\n",
    "plt.ylim([0.48,0.6])\n",
    "#plt.text(s = 'Models', size = 25, x= 8, y = 0.445)\n",
    "plt.text(s = 'Test Accuracy', size = 25, rotation = 90, x = -1.6, y = 0.515)\n",
    "plt.tick_params(axis = 'x', bottom = False)\n",
    "\n",
    "# baseline accuracy\n",
    "plt.axhline(0.5, color = 'red')\n",
    "\n",
    "# plot subdivisions\n",
    "plt.axvline(7, color = 'black')\n",
    "plt.axvline(14, color = 'black')\n",
    "\n",
    "# subdivision titles\n",
    "plt.text(s = 'CountVectorizer', size = 25, x= 1.75, y = 0.6025)\n",
    "plt.text(s = 'TfidfVectorizer', size = 25, x= 8.75, y = 0.6025)\n",
    "plt.text(s = 'Both', size = 25, x= 14.85, y = 0.6025)\n",
    "\n",
    "# highlight runneru-ups\n",
    "#runner_ups = [model_scores[i] for i in [2,6,11,12]]\n",
    "#plt.bar([3,8,13,15], runner_ups, width = 0.6, color = 'tab:blue', alpha = 0.3)\n",
    "\n",
    "\n",
    "# grid\n",
    "plt.axhline(0.525, color = 'gray', alpha = 0.5, linewidth = 0.5)\n",
    "plt.axhline(0.55, color = 'gray', alpha = 0.5, linewidth = 0.5)\n",
    "plt.axhline(0.575, color = 'gray', alpha = 0.5, linewidth = 0.5)\n",
    "\n",
    "plt.legend(fontsize = 'x-large', frameon = False);\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.savefig('images/iteration_scores.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc8bbe-c321-426c-8d5c-1328a4701923",
   "metadata": {},
   "source": [
    "As mentioned before, our Stacking model beats our other models but a signifcant margin. The fact that it incorporates four different types of models and two different string vectorizers makes me feel a bit more confident in it than other individual models. This is our production model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ce7f2-a286-4d68-ab71-597cf5d3641b",
   "metadata": {},
   "source": [
    "## Modeling On Non Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448168fc-c6d9-464c-a32e-2ee7b4f140ea",
   "metadata": {},
   "source": [
    "Before we conclude our project, we briefly explore using the non text data we collected to predict subreddits. Namely, we use the time of post column `created_utc`, the sentiment columns `sent_pos`, `sent_neg`, and `sent_compound`, and last the word count column `word_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f53506dc-238e-47ed-9ef6-13d36b9219bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nt for Non Text\n",
    "X_nt = all_posts[['created_utc', 'sent_pos', 'sent_neg', 'sent_compound', 'word_count']]\n",
    "y_nt = all_posts['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6d24afc-ab7a-48ad-a950-d54642a48a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nt, X_test_nt, y_train_nt, y_test_nt = train_test_split(X_nt, y_nt, random_state = 42, stratify = y_nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2cb7bd-a232-4ead-9f57-c67385f066bd",
   "metadata": {},
   "source": [
    "For the sake of simplicity, let us fit a logistic regression and a random forest on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "117cece4-cbae-45f9-b6ae-8bb61df763c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_nt, y_train_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ab8543c-ffca-4353-b7ad-75a32980a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5036378334680679\n",
      "0.5032310177705978\n"
     ]
    }
   ],
   "source": [
    "print(lr.score(X_train_nt, y_train_nt))\n",
    "print(lr.score(X_test_nt, y_test_nt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f8fa15-8259-4ca4-a034-ed9cd81f5bd8",
   "metadata": {},
   "source": [
    "Quite an unimpressive score! However, when we fit a random forest we obtain a score that massively outshines all of our previous work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "426c5c04-129f-4fda-ae10-1b77f8c79337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_nt, y_train_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7770ff8b-fdd0-4f19-a182-2541dcfdae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9975747776879548\n",
      "0.8368336025848142\n"
     ]
    }
   ],
   "source": [
    "print(rf.score(X_train_nt, y_train_nt))\n",
    "print(rf.score(X_test_nt, y_test_nt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "43681794-c92f-4097-bf3a-446d194bebf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_utc      0.655885\n",
       "sent_pos         0.087411\n",
       "sent_neg         0.059890\n",
       "sent_compound    0.096531\n",
       "word_count       0.100284\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(rf.feature_importances_, index = X_nt.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4cb9ed-7087-4cb4-96c6-ef67f1b328a5",
   "metadata": {},
   "source": [
    "Impressive!\n",
    "\n",
    "Suspiciously, the model's success is coming from `created_utc`. It may be the case that when we pulled our data, we had to dig deeper into one subreddit. If this is the case, the model is simply noticing information about how the data was scraped.\n",
    "\n",
    "Let us convert our UTC time to a datetime and reimplement the model using the time of day in which the post was created. If the model remains successful, this will be a great thing to notice. If not, it will be nice to rule it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc5c3879-66ab-4bfa-808f-e575d27d6708",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posts['post_hour'] = pd.to_datetime(all_posts['created_utc'], unit = 's').apply(lambda x: x.time().hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f744561-a8d0-4045-bbea-f68884568f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nt = all_posts[['post_hour', 'sent_pos', 'sent_neg', 'sent_compound', 'word_count']]\n",
    "y_nt = all_posts['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bffb2ee9-8da7-4bee-80ab-cfc7538c21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nt, X_test_nt, y_train_nt, y_test_nt = train_test_split(X_nt, y_nt, random_state = 42, stratify = y_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cda515a0-cc4c-43c6-b050-8c1489626bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_nt, y_train_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a67bf8cd-c837-4980-aedc-6bac00e75c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.535704661816222\n",
      "0.5331179321486268\n"
     ]
    }
   ],
   "source": [
    "print(lr.score(X_train_nt, y_train_nt))\n",
    "print(lr.score(X_test_nt, y_test_nt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd77f1a-4ac7-4dbb-aba9-d1c4ddf16de5",
   "metadata": {},
   "source": [
    "Interestingly, our logistic regression scores improve a fair bit and become somewhat comparable with some of the worse models we fit earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0265d75-d958-487e-969a-6049800e5de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_nt, y_train_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57f93abd-ae13-463f-a3c4-ad4455f64118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9897601724602533\n",
      "0.4991922455573506\n"
     ]
    }
   ],
   "source": [
    "print(rf.score(X_train_nt, y_train_nt))\n",
    "print(rf.score(X_test_nt, y_test_nt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a8be0-eab1-425e-955a-bc8bccf7672e",
   "metadata": {},
   "source": [
    "And as expected, our random forest score takes a massive hit along with the feature importance of the time related column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "828552c1-00f8-46c5-9ab7-015049a264b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_hour        0.161817\n",
       "sent_pos         0.208923\n",
       "sent_neg         0.141876\n",
       "sent_compound    0.239929\n",
       "word_count       0.247455\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(rf.feature_importances_, index = X_nt.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03222bf-c4c1-4b46-ba6e-af9835dbc4f9",
   "metadata": {},
   "source": [
    "As one last example to cement our production model, we fit a KNN model on this non-text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f11ee8d9-ebd3-4df2-b51b-534655a647c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             param_grid={'knn__n_neighbors': [5, 10, 15]})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pipe = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "knn_params = {\n",
    "    'knn__n_neighbors': [5,10,15]\n",
    "}\n",
    "\n",
    "knn_gs = GridSearchCV(knn_pipe, param_grid = knn_params)\n",
    "\n",
    "knn_gs.fit(X_train_nt, y_train_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1ffa733-ccb9-4f3f-af0c-5ad5a5d8d257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6108865534896254\n",
      "0.5282714054927302\n"
     ]
    }
   ],
   "source": [
    "print(knn_gs.score(X_train_nt, y_train_nt))\n",
    "print(knn_gs.score(X_test_nt, y_test_nt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4113263-4240-412c-9467-b974b65a2d27",
   "metadata": {},
   "source": [
    "After a few basic attempts to create models on the non text data, the scores do not seem to be any better than our lowest performing text based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d76e64-f1b0-49d4-b672-225d121b5cbc",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48890a7c-3cf7-4473-91ec-c85174e6a548",
   "metadata": {},
   "source": [
    "Our goals for this project were to:\n",
    "- explore the text data from posts on r/Seattle and r/SeattleWA\n",
    "- try to identify notable ways in how these two subreddits differ\n",
    "- and build classification models to try and predict if a post is more likely to come from r/Seattle or r/SeattleWA\n",
    "\n",
    "We were able to analyze some characteristics within the r/SeattleWA subreddit that distinguished it from r/Seattle. The main takeaway was that r/SeattleWA showed a lot of reason to believe its users are generally more Conservative than the users on r/Seattle. This can be seen by the significant difference in frequency of the following words, all of which appeared much more frequently in r/SeattleWA:\n",
    "- mask, tax, drug, clean, homeless, report, crime, law, wear, gun\n",
    "\n",
    "With r/Seattle, the most common words appear to be more general suggesting the subreddit consists of more general residents of Seattle.\n",
    "- board, food, game, event, dog, line, blue\n",
    "\n",
    "In terms of our production model, we tried numerous models and the one that performed the strongest was a StackingClassifier whose first level estimators consisted of a:\n",
    "- random forest with CountVectorizer\n",
    "- Gradient Boosting with CountVectorizer\n",
    "- multinomial naive Bayes with CountVectorizer\n",
    "- logistic regression with TfidfVectorizer\n",
    "- multinomial naive Bayes with TfidfVectorizer\n",
    "\n",
    "We stated that our original goal was an accuracy score exceeding 60%. Unfortunately, our production model slightly missed the target with an accuracy score of 59%. Although we were able to identify a rough distinction between the two subreddits, there are many similarities between them. It was not surprising that our models had some difficulty predicting between the two, especially with a using bag-of-words approach like CountVectorizer and TfidfVectorizer.\n",
    "\n",
    "For future explorations, I would recommend analyzing words strictly in one subreddit and not the other. In this project, we looked at the top 2,000 words of each subredit and examined the words in common. This completely ignored any words roughly 700 words (350 from each subreddit). Most of these words would likely be uninteresting, but there may be a few illustrative gems.\n",
    "\n",
    "Other topics we did not thoroughly examine were bi-grams and tri-grams. I looked into these very lightly, but not of the work was led to anything deep enough to include in the project. There may be some insights to draw here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
